{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train-Fast-style-transfer-tensorflow-ml5js.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StephenRoddy/training-styletransfer/blob/master/Train_Fast_style_transfer_tensorflow_ml5js.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfPL3z-gDHuQ"
      },
      "source": [
        "# Train and Style Transfer model and run it in ml5.js/tf.js"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcY9cMXsDL8b"
      },
      "source": [
        "## 1. Preparing your environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dkk2v3JCuEW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "bd69b33d-f184-48f9-b74f-52f218d85e0a"
      },
      "source": [
        "# Clone the fast-style-transfer git repo from github: https://github.com/lengstrom/fast-style-transfer.\n",
        "!git clone https://github.com/lengstrom/fast-style-transfer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fast-style-transfer'...\n",
            "remote: Enumerating objects: 235, done.\u001b[K\n",
            "remote: Total 235 (delta 0), reused 0 (delta 0), pack-reused 235\u001b[K\n",
            "Receiving objects: 100% (235/235), 11.02 MiB | 44.76 MiB/s, done.\n",
            "Resolving deltas: 100% (110/110), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4qwxD7ZEMgD"
      },
      "source": [
        "### Add a style image\n",
        "1. Go to left sidebar, click on the folder icon to open \"Files\" panel\n",
        "2. Create a folder called 'ckpt' inside of 'fast-style-transfer' folder\n",
        "3. Create another folder called 'images' inside of 'fast-style-transfer' folder\n",
        "4. Inside of the 'images' folder, create a folder called 'style'\n",
        "5. Put a style image inside of the 'style' folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF1kfOS9dJHF"
      },
      "source": [
        "### Install some libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jii5lBIVY1cs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "684c0ff5-516f-4d08-cda8-30f3d3b168db"
      },
      "source": [
        "# Install tensorflow\n",
        "!pip install tensorflow-gpu==2.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/93/c7bca39b23aae45cd2e85ad3871c81eccc63b9c5276e926511e2e5b0879d/tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 28kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.18.5)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.35.1)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (3.12.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 55.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.32.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 47.2MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu==2.1.0) (50.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=7527536832a7fefe2b57e7e193f6ba5bcb4d5488255dc010ba18ad7dfb8db35b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 2.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorflow-estimator, tensorboard, gast, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEctG-61ZIF6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "d6987ad1-cba1-4b82-ff15-ba456c96b97c"
      },
      "source": [
        "# Install other libraries\n",
        "!apt install ffmpeg\n",
        "!pip install moviepy\n",
        "!pip install scipy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.6/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (2.4.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.41.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from moviepy) (1.18.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-DB6canDn5B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c13c2b0-9172-4352-d26e-3ad231437e90"
      },
      "source": [
        "# go to fast-style-transfer \n",
        "%cd fast-style-transfer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fast-style-transfer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0cGgkydQV6n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9d141c88-bf3a-41ae-b14a-53c11c25fe3b"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "docs.md      \u001b[0m\u001b[01;34mexamples\u001b[0m/  \u001b[01;32msetup.sh\u001b[0m*  style.py\n",
            "evaluate.py  README.md  \u001b[01;34msrc\u001b[0m/       transform_video.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSC4tPjEImCI"
      },
      "source": [
        "# 2. Downloading Datasets\n",
        "\n",
        "The following step is downloading dataset, it may take 1 hour to finish. Keep this web tab active, and don't close it, wait util the following cell stopped loading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8shkSNWddtvm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "7410a5f2-8b1b-40b3-8d54-84e51e7cb579"
      },
      "source": [
        "!./setup.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-14 00:01:22--  http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
            "Resolving www.vlfeat.org (www.vlfeat.org)... 64.90.48.57\n",
            "Connecting to www.vlfeat.org (www.vlfeat.org)|64.90.48.57|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat [following]\n",
            "--2020-10-14 00:01:22--  https://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
            "Connecting to www.vlfeat.org (www.vlfeat.org)|64.90.48.57|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 576042600 (549M)\n",
            "Saving to: ‘imagenet-vgg-verydeep-19.mat’\n",
            "\n",
            "imagenet-vgg-veryde 100%[===================>] 549.36M  18.2MB/s    in 31s     \n",
            "\n",
            "2020-10-14 00:01:54 (17.6 MB/s) - ‘imagenet-vgg-verydeep-19.mat’ saved [576042600/576042600]\n",
            "\n",
            "--2020-10-14 00:01:54--  http://msvocds.blob.core.windows.net/coco2014/train2014.zip\n",
            "Resolving msvocds.blob.core.windows.net (msvocds.blob.core.windows.net)... 52.176.224.96\n",
            "Connecting to msvocds.blob.core.windows.net (msvocds.blob.core.windows.net)|52.176.224.96|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13510573713 (13G) [application/octet-stream]\n",
            "Saving to: ‘train2014.zip’\n",
            "\n",
            "train2014.zip       100%[===================>]  12.58G  9.39MB/s    in 23m 59s \n",
            "\n",
            "2020-10-14 00:25:54 (8.95 MB/s) - ‘train2014.zip’ saved [13510573713/13510573713]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwj2HgUlIrtH"
      },
      "source": [
        "# 3. Training with style.py\n",
        "Keep this cell running, keep the tab active and wait. It took me 2 hours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypI9UexsKiiN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0458d28-1f9f-4fac-c80c-67bc62d441b2"
      },
      "source": [
        "# Remember to replace the name after 'images/style/' to your own style image name\n",
        "# You can change the number after --epoch to change the training time, default to 2, it has to be > 0\n",
        "!python style.py --checkpoint-dir ckpt --style images/style/pollock.jpg --style-weight 1.5e2 --train-path data/train2014 --vgg-path data/imagenet-vgg-verydeep-19.mat --epochs 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-14 00:34:56.765903: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2020-10-14 00:34:56.766618: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2020-10-14 00:34:56.766644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Train set has been trimmed slightly..\n",
            "(1, 500, 750, 3)\n",
            "2020-10-14 00:35:00.608957: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-14 00:35:00.662501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-14 00:35:00.663186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P4 computeCapability: 6.1\n",
            "coreClock: 1.1135GHz coreCount: 20 deviceMemorySize: 7.43GiB deviceMemoryBandwidth: 178.99GiB/s\n",
            "2020-10-14 00:35:00.682094: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-14 00:35:00.899075: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-14 00:35:01.035568: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-14 00:35:01.056803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-14 00:35:01.324476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-14 00:35:01.346523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-14 00:35:01.861834: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-14 00:35:01.862034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-14 00:35:01.862760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-14 00:35:01.863319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2020-10-14 00:35:01.866828: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2020-10-14 00:35:01.925371: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000140000 Hz\n",
            "2020-10-14 00:35:01.925823: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16bcbc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-14 00:35:01.925862: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-14 00:35:02.078219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-14 00:35:02.078928: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16bd800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-14 00:35:02.078962: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-10-14 00:35:02.079928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-14 00:35:02.080345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P4 computeCapability: 6.1\n",
            "coreClock: 1.1135GHz coreCount: 20 deviceMemorySize: 7.43GiB deviceMemoryBandwidth: 178.99GiB/s\n",
            "2020-10-14 00:35:02.080432: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-14 00:35:02.080461: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-14 00:35:02.080499: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-14 00:35:02.080535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-14 00:35:02.080557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-14 00:35:02.080576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-14 00:35:02.080595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-14 00:35:02.080671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-14 00:35:02.081123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-14 00:35:02.081476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2020-10-14 00:35:02.084656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-14 00:35:02.085823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-14 00:35:02.085932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2020-10-14 00:35:02.085993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2020-10-14 00:35:02.096016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-14 00:35:02.097004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-14 00:35:02.097591: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-14 00:35:02.097648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "2020-10-14 00:35:18.685211: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 96000000 exceeds 10% of system memory.\n",
            "2020-10-14 00:35:19.074810: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 96000000 exceeds 10% of system memory.\n",
            "2020-10-14 00:35:19.169448: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 96000000 exceeds 10% of system memory.\n",
            "2020-10-14 00:35:19.528270: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 24000000 exceeds 10% of system memory.\n",
            "2020-10-14 00:35:19.554859: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 48000000 exceeds 10% of system memory.\n",
            "2020-10-14 00:35:26.026770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-14 00:35:26.027408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla P4 computeCapability: 6.1\n",
            "coreClock: 1.1135GHz coreCount: 20 deviceMemorySize: 7.43GiB deviceMemoryBandwidth: 178.99GiB/s\n",
            "2020-10-14 00:35:26.027519: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-14 00:35:26.027552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-14 00:35:26.027575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-14 00:35:26.027600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-14 00:35:26.027622: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-14 00:35:26.027643: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-14 00:35:26.027665: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-14 00:35:26.027752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-14 00:35:26.028276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-14 00:35:26.028793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
            "2020-10-14 00:35:26.028857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-14 00:35:26.028877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
            "2020-10-14 00:35:26.028890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
            "2020-10-14 00:35:26.029011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-14 00:35:26.029580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-14 00:35:26.030079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "UID: 67\n",
            "2020-10-14 00:35:39.462980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-14 00:35:43.959888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "Epoch 0, Iteration: 2000, Loss: 21600420.0\n",
            "style: 9736818.0, content:10145947.0, tv: 1717656.2\n",
            "Epoch 0, Iteration: 4000, Loss: 18942828.0\n",
            "style: 7947102.5, content:9734662.0, tv: 1261063.4\n",
            "Epoch 0, Iteration: 6000, Loss: 17403432.0\n",
            "style: 6731669.5, content:9566791.0, tv: 1104972.6\n",
            "Epoch 0, Iteration: 8000, Loss: 15633652.0\n",
            "style: 5753959.5, content:8855481.0, tv: 1024211.9\n",
            "Epoch 0, Iteration: 10000, Loss: 16416881.0\n",
            "style: 6082545.5, content:9347078.0, tv: 987256.94\n",
            "Epoch 0, Iteration: 12000, Loss: 15823606.0\n",
            "style: 5179434.5, content:9672174.0, tv: 971998.25\n",
            "Epoch 0, Iteration: 14000, Loss: 14615245.0\n",
            "style: 5069369.5, content:8602881.0, tv: 942994.56\n",
            "Epoch 0, Iteration: 16000, Loss: 13934085.0\n",
            "style: 4553559.0, content:8447559.0, tv: 932966.9\n",
            "Epoch 0, Iteration: 18000, Loss: 14439905.0\n",
            "style: 4333362.5, content:9171096.0, tv: 935447.4\n",
            "Epoch 0, Iteration: 20000, Loss: 14053514.0\n",
            "style: 4463182.0, content:8680942.0, tv: 909390.3\n",
            "Epoch 1, Iteration: 2000, Loss: 14218809.0\n",
            "style: 4155628.5, content:9163561.0, tv: 899619.2\n",
            "Epoch 1, Iteration: 4000, Loss: 13954946.0\n",
            "style: 4056411.2, content:9006329.0, tv: 892206.44\n",
            "Epoch 1, Iteration: 6000, Loss: 13430049.0\n",
            "style: 3702505.2, content:8846809.0, tv: 880735.44\n",
            "Epoch 1, Iteration: 8000, Loss: 12690987.0\n",
            "style: 3553138.5, content:8262005.5, tv: 875842.8\n",
            "Epoch 1, Iteration: 10000, Loss: 13328570.0\n",
            "style: 3671889.5, content:8780859.0, tv: 875821.75\n",
            "Epoch 1, Iteration: 12000, Loss: 13194232.0\n",
            "style: 3359389.5, content:8966411.0, tv: 868432.25\n",
            "Epoch 1, Iteration: 14000, Loss: 12684909.0\n",
            "style: 3588194.2, content:8226389.0, tv: 870326.06\n",
            "Epoch 1, Iteration: 16000, Loss: 12180174.0\n",
            "style: 3318123.2, content:7999678.0, tv: 862373.4\n",
            "Epoch 1, Iteration: 18000, Loss: 12772390.0\n",
            "style: 3333563.8, content:8576797.0, tv: 862029.3\n",
            "Epoch 1, Iteration: 20000, Loss: 12533873.0\n",
            "style: 3511217.2, content:8170564.0, tv: 852091.94\n",
            "Epoch 1, Iteration: 20695, Loss: 12377230.0\n",
            "style: 3308773.2, content:8215977.0, tv: 852480.3\n",
            "Training complete. For evaluation:\n",
            "    `python evaluate.py --checkpoint ckpt ...`\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQX2AeuXd-LB"
      },
      "source": [
        "At this point, you will be able to see 4 files in the '/fast-style-transfer/ckpt' folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziBLDaHSIr_2"
      },
      "source": [
        "# 4. Converting model to ml5js"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "903jSW-5WlAr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "8e02a36a-aef4-4891-e011-dfc27db47eb9"
      },
      "source": [
        "pip install tensorflow==1.14.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.12.4)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.35.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 59.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.0)\n",
            "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.1.0 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 2.1.1\n",
            "    Uninstalling tensorboard-2.1.1:\n",
            "      Successfully uninstalled tensorboard-2.1.1\n",
            "  Found existing installation: tensorflow-estimator 2.1.0\n",
            "    Uninstalling tensorflow-estimator-2.1.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW2jDqCOX7Un",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e0cae064-e7f4-4776-fed4-73d1e8516125"
      },
      "source": [
        "%cd ../\n",
        "!git clone https://github.com/reiinakano/fast-style-transfer-deeplearnjs.git\n",
        "%cd fast-style-transfer-deeplearnjs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'fast-style-transfer-deeplearnjs'...\n",
            "remote: Enumerating objects: 1407, done.\u001b[K\n",
            "remote: Total 1407 (delta 0), reused 0 (delta 0), pack-reused 1407\u001b[K\n",
            "Receiving objects: 100% (1407/1407), 37.97 MiB | 1.56 MiB/s, done.\n",
            "Resolving deltas: 100% (135/135), done.\n",
            "/content/fast-style-transfer-deeplearnjs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6ky6qQhYJBz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60d8c1b8-4dfc-4d67-cea7-15a18695e140"
      },
      "source": [
        "# Change src/ckpts/pollock to src/ckpts/YOUR_OWN_FOLDER\n",
        "!python scripts/dump_checkpoint_vars.py --output_dir=src/ckpts/pollock --checkpoint_file=../fast-style-transfer/ckpt/fns.ckpt\n",
        "# Change src/ckpts/pollock to src/ckpts/YOUR_OWN_FOLDER\n",
        "!python scripts/remove_optimizer_variables.py --output_dir=src/ckpts/pollock"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From scripts/dump_checkpoint_vars.py:48: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "WARNING:tensorflow:From scripts/dump_checkpoint_vars.py:51: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "Writing variable Variable_9/Adam_1...\n",
            "Writing variable Variable_8/Adam...\n",
            "Writing variable Variable_8...\n",
            "Writing variable Variable_7/Adam_1...\n",
            "Writing variable Variable_7/Adam...\n",
            "Writing variable Variable_7...\n",
            "Writing variable Variable_6/Adam...\n",
            "Writing variable Variable_6...\n",
            "Writing variable Variable_5/Adam...\n",
            "Writing variable Variable_47/Adam_1...\n",
            "Writing variable Variable_45/Adam_1...\n",
            "Writing variable Variable_45/Adam...\n",
            "Writing variable Variable_45...\n",
            "Writing variable Variable_43/Adam_1...\n",
            "Writing variable Variable_43/Adam...\n",
            "Writing variable Variable_43...\n",
            "Writing variable Variable_5/Adam_1...\n",
            "Writing variable Variable_42/Adam...\n",
            "Writing variable Variable_41/Adam...\n",
            "Writing variable Variable_41...\n",
            "Writing variable Variable_40...\n",
            "Writing variable Variable_39/Adam_1...\n",
            "Writing variable Variable_39...\n",
            "Writing variable Variable_38/Adam_1...\n",
            "Writing variable Variable_4/Adam_1...\n",
            "Writing variable Variable_38...\n",
            "Writing variable Variable_44...\n",
            "Writing variable Variable_20/Adam...\n",
            "Writing variable Variable_10/Adam...\n",
            "Writing variable Variable_37/Adam...\n",
            "Writing variable Variable_31/Adam...\n",
            "Writing variable Variable_19/Adam...\n",
            "Writing variable Variable_25...\n",
            "Writing variable Variable_9...\n",
            "Writing variable Variable_32/Adam...\n",
            "Writing variable Variable_34...\n",
            "Writing variable Variable_5...\n",
            "Writing variable Variable_47/Adam...\n",
            "Writing variable Variable_17/Adam_1...\n",
            "Writing variable Variable_32...\n",
            "Writing variable Variable_18/Adam...\n",
            "Writing variable Variable_17/Adam...\n",
            "Writing variable Variable_19/Adam_1...\n",
            "Writing variable Variable_11/Adam_1...\n",
            "Writing variable Variable_17...\n",
            "Writing variable Variable_18...\n",
            "Writing variable Variable_44/Adam_1...\n",
            "Writing variable Variable_36...\n",
            "Writing variable Variable_16...\n",
            "Writing variable Variable_2...\n",
            "Writing variable Variable_14/Adam_1...\n",
            "Writing variable beta2_power...\n",
            "Writing variable Variable_15...\n",
            "Writing variable Variable_30...\n",
            "Writing variable Variable_15/Adam_1...\n",
            "Writing variable Variable_46...\n",
            "Writing variable Variable_15/Adam...\n",
            "Writing variable Variable_24/Adam...\n",
            "Writing variable Variable_16/Adam...\n",
            "Writing variable Variable_11...\n",
            "Writing variable Variable_2/Adam_1...\n",
            "Writing variable Variable_41/Adam_1...\n",
            "Writing variable Variable_38/Adam...\n",
            "Writing variable Variable_23...\n",
            "Writing variable Variable_10/Adam_1...\n",
            "Writing variable Variable_24...\n",
            "Writing variable Variable_37/Adam_1...\n",
            "Writing variable Variable_47...\n",
            "Writing variable Variable_14...\n",
            "Writing variable Variable_20...\n",
            "Writing variable Variable_30/Adam...\n",
            "Writing variable Variable_1/Adam...\n",
            "Writing variable Variable_29/Adam_1...\n",
            "Writing variable Variable/Adam_1...\n",
            "Writing variable Variable_19...\n",
            "Writing variable Variable_21/Adam_1...\n",
            "Writing variable Variable_11/Adam...\n",
            "Writing variable Variable_29...\n",
            "Writing variable Variable_22...\n",
            "Writing variable Variable_16/Adam_1...\n",
            "Writing variable beta1_power...\n",
            "Writing variable Variable_40/Adam_1...\n",
            "Writing variable Variable_1...\n",
            "Writing variable Variable_44/Adam...\n",
            "Writing variable Variable_12...\n",
            "Writing variable Variable_36/Adam...\n",
            "Writing variable Variable/Adam...\n",
            "Writing variable Variable_25/Adam...\n",
            "Writing variable Variable_12/Adam_1...\n",
            "Writing variable Variable_23/Adam_1...\n",
            "Writing variable Variable_12/Adam...\n",
            "Writing variable Variable_21...\n",
            "Writing variable Variable_27...\n",
            "Writing variable Variable_4...\n",
            "Writing variable Variable_37...\n",
            "Writing variable Variable_10...\n",
            "Writing variable Variable_13...\n",
            "Writing variable Variable_28/Adam...\n",
            "Writing variable Variable_33/Adam_1...\n",
            "Writing variable Variable_13/Adam_1...\n",
            "Writing variable Variable_14/Adam...\n",
            "Writing variable Variable_3/Adam_1...\n",
            "Writing variable Variable_18/Adam_1...\n",
            "Writing variable Variable_2/Adam...\n",
            "Writing variable Variable_31/Adam_1...\n",
            "Writing variable Variable_9/Adam...\n",
            "Writing variable Variable_42/Adam_1...\n",
            "Writing variable Variable_22/Adam...\n",
            "Writing variable Variable_6/Adam_1...\n",
            "Writing variable Variable_22/Adam_1...\n",
            "Writing variable Variable_23/Adam...\n",
            "Writing variable Variable_28/Adam_1...\n",
            "Writing variable Variable_35/Adam_1...\n",
            "Writing variable Variable_20/Adam_1...\n",
            "Writing variable Variable_26/Adam...\n",
            "Writing variable Variable_40/Adam...\n",
            "Writing variable Variable_4/Adam...\n",
            "Writing variable Variable_30/Adam_1...\n",
            "Writing variable Variable_33/Adam...\n",
            "Writing variable Variable_26/Adam_1...\n",
            "Writing variable Variable_26...\n",
            "Writing variable Variable_27/Adam_1...\n",
            "Writing variable Variable_1/Adam_1...\n",
            "Writing variable Variable_29/Adam...\n",
            "Writing variable Variable_25/Adam_1...\n",
            "Writing variable Variable_28...\n",
            "Writing variable Variable_3...\n",
            "Writing variable Variable_42...\n",
            "Writing variable Variable_39/Adam...\n",
            "Writing variable Variable_3/Adam...\n",
            "Writing variable Variable_31...\n",
            "Writing variable Variable_8/Adam_1...\n",
            "Writing variable Variable_21/Adam...\n",
            "Writing variable Variable_32/Adam_1...\n",
            "Writing variable Variable_13/Adam...\n",
            "Writing variable Variable_27/Adam...\n",
            "Writing variable Variable_33...\n",
            "Writing variable Variable_34/Adam...\n",
            "Writing variable Variable_34/Adam_1...\n",
            "Writing variable Variable_46/Adam_1...\n",
            "Writing variable Variable_24/Adam_1...\n",
            "Writing variable Variable_35...\n",
            "Writing variable Variable_35/Adam...\n",
            "Writing variable Variable_46/Adam...\n",
            "Writing variable Variable...\n",
            "Writing variable Variable_36/Adam_1...\n",
            "Writing manifest to src/ckpts/pollock/manifest.json\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePy-deklNSHZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCt42jBqY_rA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "1540202d-537c-49ab-8675-b3a0ac321ae4"
      },
      "source": [
        "!zip -r /content/fast-style-transfer-deeplearnjs/src/ckpts/pollock.zip /content/fast-style-transfer-deeplearnjs/src/ckpts/pollock"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/ (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_47 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_25 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_43 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_13 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_28 (deflated 2%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_40 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_37 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_26 (deflated 4%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_23 (deflated 4%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_41 (deflated 1%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_11 (deflated 4%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_7 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_36 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_12 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_14 (deflated 2%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_17 (deflated 5%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_5 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_32 (deflated 5%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_42 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_10 (deflated 2%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_29 (deflated 5%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_20 (deflated 3%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_44 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_34 (deflated 2%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_1 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_33 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_9 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_45 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_22 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_6 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_18 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_16 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_46 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_15 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_4 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_21 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_19 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_38 (deflated 4%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_24 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/manifest.json (deflated 91%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_8 (deflated 1%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_35 (deflated 6%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_27 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_2 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_30 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_3 (deflated 7%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_31 (stored 0%)\n",
            "  adding: content/fast-style-transfer-deeplearnjs/src/ckpts/pollock/Variable_39 (deflated 7%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8_X2DJIMiJW"
      },
      "source": [
        "# 5. Run it with ml5js\n",
        "Now, you should be able to see a 'pollock' .zip file at \"fast-style-transfer-deeplearnjs/src/ckpts/pollock.zip\". (Sometimes, you need to refresh the Files panel, right click to refresh)\n",
        "\n",
        "Download the 'pollock' folder and put it into your p5 sketch(https://github.com/yining1023/machine-learning-for-the-web/tree/master/week5-styleTransfer/styleTransfer-ml5/StyleTransfer_Video) under models/.\n",
        "\n",
        "Change the model path in your p5 sketch: style = ml5.styleTransfer('models/pollock', video, modelLoaded);"
      ]
    }
  ]
}